{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Shuffled Answer for Science MCQ (5 options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 answer corrections:\n",
      "Question | Original Answer -> New Answer\n",
      "----------------------------------------\n",
      "Q 1     | D              -> B\n",
      "Q 2     | A              -> A\n",
      "Q 3     | C              -> D\n",
      "Q 4     | D              -> C\n",
      "Q 5     | A              -> A\n",
      "Q 6     | D              -> E\n",
      "Q 7     | C              -> D\n",
      "Q 8     | A              -> B\n",
      "Q 9     | E              -> E\n",
      "Q10     | A              -> A\n",
      "\n",
      "Total questions processed: 5000\n",
      "\n",
      "Number of answers that changed: 4046\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_options(prompt_text):\n",
    "    \"\"\"Extract options from the prompt text as a dictionary.\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    options = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Modified to handle any single letter followed by )\n",
    "        if len(line) > 2 and line[1] == ')' and line[0].isalpha():\n",
    "            option_letter = line[0]\n",
    "            option_text = line[2:].strip()  # Skip the letter and ) and trim whitespace\n",
    "            options[option_letter] = option_text\n",
    "            \n",
    "    return options\n",
    "\n",
    "def find_correct_answer_letter(original_options, shuffled_options, original_answer_letter):\n",
    "    \"\"\"Find the new letter for the correct answer in the shuffled options.\"\"\"\n",
    "    try:\n",
    "        # Get the correct answer text from original options\n",
    "        original_answer_text = original_options[original_answer_letter]\n",
    "        \n",
    "        # Find which letter in shuffled options has this same text\n",
    "        for letter, text in shuffled_options.items():\n",
    "            if text == original_answer_text:\n",
    "                return letter\n",
    "                \n",
    "        print(f\"Warning: Could not find matching text for answer '{original_answer_text}'\")\n",
    "        return None\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Warning: Answer letter '{original_answer_letter}' not found in options\")\n",
    "        return None\n",
    "\n",
    "def process_mcq_datasets(original_df, shuffled_df):\n",
    "    \"\"\"Process both datasets and return list of new correct answer letters.\"\"\"\n",
    "    new_answers = []\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(len(original_df)):\n",
    "        try:\n",
    "            # Get original and shuffled prompts for this question\n",
    "            original_prompt = original_df.iloc[i]['prompt']\n",
    "            shuffled_prompt = shuffled_df.iloc[i]['prompt']\n",
    "            original_answer = original_df.iloc[i]['answer']\n",
    "            \n",
    "            # Extract options from both prompts\n",
    "            original_options = extract_options(original_prompt)\n",
    "            shuffled_options = extract_options(shuffled_prompt)\n",
    "            \n",
    "            # Find new correct answer letter\n",
    "            new_answer = find_correct_answer_letter(original_options, shuffled_options, original_answer)\n",
    "            \n",
    "            if new_answer is None:\n",
    "                errors.append(i)\n",
    "                new_answer = original_answer  # Keep original answer if mapping fails\n",
    "                \n",
    "            new_answers.append(new_answer)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {i+1}: {str(e)}\")\n",
    "            errors.append(i)\n",
    "            new_answers.append(None)\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\nWarning: Had issues processing {len(errors)} questions\")\n",
    "        print(f\"First few problematic question indices: {errors[:5]}\")\n",
    "    \n",
    "    return new_answers\n",
    "\n",
    "# Read the actual CSV files\n",
    "try:\n",
    "    original_df = pd.read_csv(\"../../Original_Datasets/ScienceMCQ_5000_sample.csv\")\n",
    "    shuffled_df = pd.read_csv(\"../../Shuffled_Datasets/SHUFFLED_ScienceMCQ_5000_sample.csv\")\n",
    "    \n",
    "    # Process the datasets\n",
    "    corrected_answers = process_mcq_datasets(original_df, shuffled_df)\n",
    "    \n",
    "    # Print first few entries as a sanity check\n",
    "    print(\"\\nFirst 10 answer corrections:\")\n",
    "    print(\"Question | Original Answer -> New Answer\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (orig, new) in enumerate(zip(original_df['answer'][:10], corrected_answers[:10]), 1):\n",
    "        print(f\"Q{i:2d}     | {orig:14s} -> {new}\")\n",
    "    \n",
    "    print(f\"\\nTotal questions processed: {len(corrected_answers)}\")\n",
    "    \n",
    "    # Save problematic questions for review\n",
    "    problem_questions = [\n",
    "        (i, original_df.iloc[i]['prompt'], original_df.iloc[i]['answer'], corrected_answers[i])\n",
    "        for i in range(len(corrected_answers))\n",
    "        if corrected_answers[i] != original_df.iloc[i]['answer']\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nNumber of answers that changed: {len(problem_questions)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: One or both CSV files not found. Please check the file paths.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated shuffled dataset with corrected answers!\n",
      "\n",
      "First 5 rows of updated dataset:\n",
      "                                              prompt answer\n",
      "0  Question: Which of the following statements ac...      B\n",
      "1  Question: Which of the following is an accurat...      A\n",
      "2  Question: What is the significance of regulari...      D\n",
      "3  Question: Which of the following statements ac...      C\n",
      "4  Question: Which of the following statements ac...      A\n"
     ]
    }
   ],
   "source": [
    "# Read the shuffled dataset\n",
    "shuffled_df = pd.read_csv(\"../../Shuffled_Datasets/SHUFFLED_ScienceMCQ_5000_sample.csv\")\n",
    "\n",
    "# Update the answer column with corrected answers\n",
    "shuffled_df['answer'] = corrected_answers\n",
    "\n",
    "# Save the updated dataset\n",
    "shuffled_df.to_csv(\"../../Shuffled_Datasets/SHUFFLED_ScienceMCQ_5000_sample.csv\", index=False)\n",
    "\n",
    "print(\"Updated shuffled dataset with corrected answers!\")\n",
    "\n",
    "# Print first few rows as a sanity check\n",
    "print(\"\\nFirst 5 rows of updated dataset:\")\n",
    "print(shuffled_df[['prompt', 'answer']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying first 5 updates:\n",
      "Question 1: correct_answer_1 = B\n",
      "Question 2: correct_answer_2 = A\n",
      "Question 3: correct_answer_3 = D\n",
      "Question 4: correct_answer_4 = C\n",
      "Question 5: correct_answer_5 = A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('gpt_logprob_Science_position.json', 'r') as file:\n",
    "    logprob_data = json.load(file)\n",
    "\n",
    "# Update each item with the correct field name\n",
    "for i, item in enumerate(logprob_data):\n",
    "    # The field name changes for each question (correct_answer_1, correct_answer_2, etc.)\n",
    "    answer_field = f\"correct_answer_{i+1}\"\n",
    "    if answer_field in item and i < len(corrected_answers):\n",
    "        item[answer_field] = corrected_answers[i]\n",
    "\n",
    "# Save the updated JSON\n",
    "with open('gpt_logprob_Science_position.json', 'w') as file:\n",
    "    json.dump(logprob_data, file, indent=4)\n",
    "\n",
    "# Verify the update\n",
    "print(\"Verifying first 5 updates:\")\n",
    "for i in range(5):\n",
    "    if i < len(logprob_data):\n",
    "        answer_field = f\"correct_answer_{i+1}\"\n",
    "        print(f\"Question {i+1}: {answer_field} = {logprob_data[i][answer_field]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Shuffled Answer for Med/MMLU MCQ (4 options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 answer corrections:\n",
      "Question | Original Answer -> New Answer\n",
      "----------------------------------------\n",
      "Q 1     | C              -> A\n",
      "Q 2     | B              -> B\n",
      "Q 3     | D              -> A\n",
      "Q 4     | C              -> C\n",
      "Q 5     | B              -> C\n",
      "Q 6     | C              -> B\n",
      "Q 7     | C              -> B\n",
      "Q 8     | A              -> A\n",
      "Q 9     | A              -> D\n",
      "Q10     | B              -> A\n",
      "\n",
      "Total questions processed: 5000\n",
      "\n",
      "Number of answers that changed: 3727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_options(prompt_text):\n",
    "    \"\"\"Extract options A through D from the prompt text as a dictionary.\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    options = {}\n",
    "    valid_options = {'A', 'B', 'C', 'D'}\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if len(line) > 2 and line[1] == ')' and line[0] in valid_options:\n",
    "            option_letter = line[0]\n",
    "            option_text = line[2:].strip()  # Skip the letter and ) and trim whitespace\n",
    "            options[option_letter] = option_text\n",
    "            \n",
    "    # Validate that we have all options A-D\n",
    "    if not all(opt in options for opt in valid_options):\n",
    "        missing = valid_options - set(options.keys())\n",
    "        raise ValueError(f\"Missing options: {missing}\")\n",
    "            \n",
    "    return options\n",
    "\n",
    "def find_correct_answer_letter(original_options, shuffled_options, original_answer_letter):\n",
    "    \"\"\"Find the new letter for the correct answer in the shuffled options.\"\"\"\n",
    "    if original_answer_letter not in {'A', 'B', 'C', 'D'}:\n",
    "        raise ValueError(f\"Invalid answer letter: {original_answer_letter}\")\n",
    "        \n",
    "    try:\n",
    "        # Get the correct answer text from original options\n",
    "        original_answer_text = original_options[original_answer_letter]\n",
    "        \n",
    "        # Find which letter in shuffled options has this same text\n",
    "        for letter, text in shuffled_options.items():\n",
    "            if text == original_answer_text:\n",
    "                return letter\n",
    "                \n",
    "        raise ValueError(f\"Could not find matching text for answer '{original_answer_text}'\")\n",
    "        \n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Answer letter '{original_answer_letter}' not found in options\")\n",
    "\n",
    "def process_mcq_datasets(original_df, shuffled_df):\n",
    "    \"\"\"Process both datasets and return list of new correct answer letters.\"\"\"\n",
    "    new_answers = []\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(len(original_df)):\n",
    "        try:\n",
    "            # Get original and shuffled prompts for this question\n",
    "            original_prompt = original_df.iloc[i]['prompt']\n",
    "            shuffled_prompt = shuffled_df.iloc[i]['prompt']\n",
    "            original_answer = original_df.iloc[i]['answer']\n",
    "            \n",
    "            # Validate the original answer\n",
    "            if original_answer not in {'A', 'B', 'C', 'D'}:\n",
    "                raise ValueError(f\"Invalid original answer: {original_answer}\")\n",
    "            \n",
    "            # Extract options from both prompts\n",
    "            original_options = extract_options(original_prompt)\n",
    "            shuffled_options = extract_options(shuffled_prompt)\n",
    "            \n",
    "            # Find new correct answer letter\n",
    "            new_answer = find_correct_answer_letter(original_options, shuffled_options, original_answer)\n",
    "            new_answers.append(new_answer)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {i+1}: {str(e)}\")\n",
    "            errors.append(i)\n",
    "            new_answers.append(original_df.iloc[i]['answer'])  # Keep original answer if processing fails\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\nWarning: Had issues processing {len(errors)} questions\")\n",
    "        print(f\"First few problematic question indices: {errors[:5]}\")\n",
    "    \n",
    "    return new_answers\n",
    "\n",
    "# Read the actual CSV files\n",
    "try:\n",
    "    original_df = pd.read_csv(\"../../Original_Datasets/MMLU_5000_sample.csv\")\n",
    "    shuffled_df = pd.read_csv(\"../../Shuffled_Datasets/SHUFFLED_MMLU_5000_sample.csv\")\n",
    "    \n",
    "    # Process the datasets\n",
    "    corrected_answers = process_mcq_datasets(original_df, shuffled_df)\n",
    "    \n",
    "    # Print first few entries as a sanity check\n",
    "    print(\"\\nFirst 10 answer corrections:\")\n",
    "    print(\"Question | Original Answer -> New Answer\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (orig, new) in enumerate(zip(original_df['answer'][:10], corrected_answers[:10]), 1):\n",
    "        print(f\"Q{i:2d}     | {orig:14s} -> {new}\")\n",
    "    \n",
    "    print(f\"\\nTotal questions processed: {len(corrected_answers)}\")\n",
    "    \n",
    "    # Save problematic questions for review\n",
    "    problem_questions = [\n",
    "        (i, original_df.iloc[i]['prompt'], original_df.iloc[i]['answer'], corrected_answers[i])\n",
    "        for i in range(len(corrected_answers))\n",
    "        if corrected_answers[i] != original_df.iloc[i]['answer']\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nNumber of answers that changed: {len(problem_questions)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: One or both CSV files not found. Please check the file paths.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated shuffled dataset with corrected answers!\n",
      "\n",
      "First 5 rows of updated dataset:\n",
      "                                              prompt answer\n",
      "0  Question: An important source of information o...      A\n",
      "1  Question: In preparation for a writing unit on...      B\n",
      "2  Question: Paper will burn at approximately wha...      A\n",
      "3  Question: The Apple iMac computer is available...      C\n",
      "4  Question: What were the first names of the ear...      C\n"
     ]
    }
   ],
   "source": [
    "# Read the shuffled dataset\n",
    "shuffled_df = pd.read_csv(\"../../Shuffled_Datasets/SHUFFLED_MMLU_5000_sample.csv\")\n",
    "\n",
    "# Update the answer column with corrected answers\n",
    "shuffled_df['answer'] = corrected_answers\n",
    "\n",
    "# Save the updated dataset\n",
    "shuffled_df.to_csv(\"../../Shuffled_Datasets/SHUFFLED_MMLU_5000_sample.csv\", index=False)\n",
    "\n",
    "print(\"Updated shuffled dataset with corrected answers!\")\n",
    "\n",
    "# Print first few rows as a sanity check\n",
    "print(\"\\nFirst 5 rows of updated dataset:\")\n",
    "print(shuffled_df[['prompt', 'answer']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying first 5 updates:\n",
      "Question 1: correct_answer_1 = A\n",
      "Question 2: correct_answer_2 = B\n",
      "Question 3: correct_answer_3 = A\n",
      "Question 4: correct_answer_4 = C\n",
      "Question 5: correct_answer_5 = C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('gpt_logprob_MMLU_position.json', 'r') as file:\n",
    "    logprob_data = json.load(file)\n",
    "\n",
    "# Update each item with the correct field name\n",
    "for i, item in enumerate(logprob_data):\n",
    "    # The field name changes for each question (correct_answer_1, correct_answer_2, etc.)\n",
    "    answer_field = f\"correct_answer_{i+1}\"\n",
    "    if answer_field in item and i < len(corrected_answers):\n",
    "        item[answer_field] = corrected_answers[i]\n",
    "\n",
    "# Save the updated JSON\n",
    "with open('gpt_logprob_MMLU_position.json', 'w') as file:\n",
    "    json.dump(logprob_data, file, indent=4)\n",
    "\n",
    "# Verify the update\n",
    "print(\"Verifying first 5 updates:\")\n",
    "for i in range(5):\n",
    "    if i < len(logprob_data):\n",
    "        answer_field = f\"correct_answer_{i+1}\"\n",
    "        print(f\"Question {i+1}: {answer_field} = {logprob_data[i][answer_field]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
